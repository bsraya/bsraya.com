---
title: 'Part 4: Stochastic Gradient Descent'
type: 'blog'
date: 2022-02-26
published: false
description: 'A Stochastic Gradient Descent implementation with Linear Regression in Python'
tags: ['Machine Learning', 'Optimization', 'Python']
---

import { Link } from 'gatsby';

This is part 3 of the series on Gradient Descent.

- <Link to="/blog/part-1-mathematics-of-gradient-descent">
    Part 1: Mathematics of Gradient Descent
  </Link>
- <Link to="/blog/part-2-batch-gradient-descent">
    Part 2: Batch Gradient Descent
  </Link>
- <Link to="/blog/part-3-mini-batch-gradient-descent">
    Part 3: Mini-Batch Gradient Descent
  </Link>

Previously, we have learned that Batch Gradient Descent only updates the parameters only after it has seen the entire dataset.
However, in this post, we are going to implement Mini-Batch Gradient Descent where it updates the parameters after it has seen a fraction of a dataset.
Not only that, we are going to find out the best batch size to make the algorithm converge faster.

# Conclusion

If you want to know how to implement it in more details, please [click here](https://www.kaggle.com/bijonsetyawan/stochastic-gradient-descent) to check the Python notebook on Kaggle.

# References

1. O. Artem. _Stochastic, Batch, and Mini-Batch Gradient Descent_. Source [https://towardsdatascience.com/stochastic-batch-and-mini-batch-gradient-descent-demystified-8b28978f7f5](https://towardsdatascience.com/stochastic-batch-and-mini-batch-gradient-descent-demystified-8b28978f7f5)
2. P. Sushant. _Batch, Mini Batch, and Stochastic Gradient Descent_. Source [https://towardsdatascience.com/batch-mini-batch-stochastic-gradient-descent-7a62ecba642a](https://towardsdatascience.com/batch-mini-batch-stochastic-gradient-descent-7a62ecba642a)
3. Geeksforgeeks. _Difference between Batch Gradient Descent and Stochastic Gradient Descent_. Source [https://www.geeksforgeeks.org/difference-between-batch-gradient-descent-and-stochastic-gradient-descent/](https://www.geeksforgeeks.org/difference-between-batch-gradient-descent-and-stochastic-gradient-descent/)
4. Sweta. _Batch, Mini Batch, and Stochastic Gradient Descent_. Source [https://sweta-nit.medium.com/batch-mini-batch-and-stochastic-gradient-descent-e9bc4cacd461](https://sweta-nit.medium.com/batch-mini-batch-and-stochastic-gradient-descent-e9bc4cacd461)
