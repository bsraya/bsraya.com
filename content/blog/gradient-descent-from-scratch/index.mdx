---
title: Gradient Descent from Scratch
type: 'portfolio'
date: 2021-12-16
published: true
description: 'Gradient Descent implementations with Linear Regression'
tags: ['Optimization', 'Python']
---

In this post, we are going to create three versions on Gradient Descent implementation, such as:

1. Gradient Descent
2. Mini-Batch Gradient Descent
3. Stochastic Gradient Descent

There are several equations that we need to familiar with before working on these implementations.

The first one is Mean Squared Error, or MSE, which is the cost function we are going to minimize.

$$
    \text{MSE} = \frac{1}{N} \sum_{i=1}^N (\text{predicted} - \text{actual})^2
$$

# 1. Gradient Descent

# 2. Mini-Batch Gradient Descent

# 3. Stochastic Gradient Descent
